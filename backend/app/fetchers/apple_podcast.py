import feedparser
import re
import hashlib
from datetime import datetime, timedelta
from .base import BaseFetcher, FetchedItem


class ApplePodcastFetcher(BaseFetcher):
    """Apple Podcast ä¸­æ–‡æ’­å®¢æ•°æ®è·å–"""

    name = "apple_podcast"
    name_zh = "ä¸­æ–‡æ’­å®¢"
    icon = "ğŸ§"
    color = "#9933FF"

    # ä¸­æ–‡ AI/ç§‘æŠ€æ’­å®¢ RSS æº
    PODCASTS = {
        # åŸæœ‰æ’­å®¢
        "https://harddecisions.fireside.fm/rss": "ç¡¬åœ°éª‡å®¢",
        "https://etw.fm/feed": "å£°ä¸œå‡»è¥¿",
        "https://crazy.capital/feed": "ç–¯æŠ•åœˆ",
        "https://dao.fm/feed/": "æ´¥æ´¥ä¹é“",
        "https://feeds.fireside.fm/zheshangye/rss": "å•†ä¸šå°±æ˜¯è¿™æ ·",
        # æ–°å¢æ’­å®¢
        "https://feed.xyzfm.space/evgg6xle9rdc": "42ç« ç»",
        "https://feed.xyzfm.space/yxuruh3f9mc4": "ä¹±ç¿»ä¹¦",
        "https://feeds.fireside.fm/guiguzaozhidao/rss": "ç¡…è°·æ—©çŸ¥é“/ç§‘æŠ€æ—©çŸ¥é“",
        "https://www.ximalaya.com/album/75918257.xml": "ç§‘æŠ€æ²‰æ€å½•",
        "https://feed.xyzfm.space/dk4yh3pkpjp3": "å¼ å°çºï½œå•†ä¸šè®¿è°ˆå½•",
        "https://feeds.fireside.fm/sv101/rss": "ç¡…è°·101",
        "https://feed.xyzfm.space/xxg7ryklkkft": "OnBoard!",
        "https://www.ximalaya.com/album/74194808.xml": "AIç‚¼é‡‘æœ¯",
    }

    AI_KEYWORDS = [
        "AI", "äººå·¥æ™ºèƒ½", "GPT", "ChatGPT", "å¤§æ¨¡å‹", "LLM",
        "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "OpenAI", "Anthropic", "Claude",
        "AGI", "AIGC", "ç”Ÿæˆå¼", "æ™ºèƒ½", "Agent", "æ™ºèƒ½ä½“",
        "Sora", "Midjourney", "ç§‘æŠ€", "æŠ€æœ¯", "åˆ›ä¸š", "ç¡…è°·",
    ]

    def fetch(self) -> list[FetchedItem]:
        items = []
        cutoff_time = datetime.now() - timedelta(hours=168)  # 7å¤©å†…

        for rss_url, podcast_name in self.PODCASTS.items():
            try:
                episodes = self._fetch_podcast(rss_url, podcast_name, cutoff_time)
                items.extend(episodes)
                print(f"[ApplePodcast] Fetched {len(episodes)} from {podcast_name}")
            except Exception as e:
                print(f"[ApplePodcast] Error fetching {podcast_name}: {e}")

        items.sort(key=lambda x: x.pub_date or "", reverse=True)

        for idx, item in enumerate(items):
            base_score = max(100 - idx * 5, 10)
            ai_relevance = self._calculate_ai_relevance(item.title)
            item.fame_score = base_score + ai_relevance

        items.sort(key=lambda x: x.fame_score, reverse=True)
        return items[:15]

    def _fetch_podcast(self, rss_url: str, podcast_name: str, cutoff_time: datetime) -> list[FetchedItem]:
        feed = feedparser.parse(rss_url)
        items = []

        for entry in feed.entries[:10]:
            try:
                pub_date = None
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    pub_date = datetime(*entry.published_parsed[:6])
                elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
                    pub_date = datetime(*entry.updated_parsed[:6])

                if pub_date and pub_date < cutoff_time:
                    continue

                audio_url = ""
                if hasattr(entry, "enclosures") and entry.enclosures:
                    for enc in entry.enclosures:
                        if "audio" in enc.get("type", ""):
                            audio_url = enc.get("href", "")
                            break

                episode_id = hashlib.md5(entry.get("link", entry.get("id", "")).encode()).hexdigest()[:12]

                thumbnail = ""
                if hasattr(entry, "image") and entry.image:
                    thumbnail = entry.image.get("href", "")
                elif hasattr(feed.feed, "image") and feed.feed.image:
                    thumbnail = feed.feed.image.get("href", "")

                duration = entry.get("itunes_duration", "N/A")

                item = FetchedItem(
                    id=episode_id,
                    title=entry.get("title", ""),
                    link=entry.get("link", ""),
                    source=podcast_name,
                    author=podcast_name,
                    pub_date=pub_date.isoformat() if pub_date else "",
                    thumbnail=thumbnail,
                    summary=self._clean_summary(entry.get("summary", "")),
                    extra={
                        "audio_url": audio_url,
                        "duration": duration,
                        "podcast_name": podcast_name,
                    }
                )
                items.append(item)

            except Exception as e:
                print(f"[ApplePodcast] Error parsing entry: {e}")

        return items

    def _clean_summary(self, summary: str) -> str:
        clean = re.sub(r'<[^>]+>', '', summary)
        clean = clean.strip()[:500]
        return clean

    def _calculate_ai_relevance(self, title: str) -> int:
        score = 0
        for keyword in self.AI_KEYWORDS:
            if keyword.lower() in title.lower():
                score += 15
        return min(score, 60)
