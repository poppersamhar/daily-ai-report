import requests
import feedparser
import re
from bs4 import BeautifulSoup
from .base import BaseFetcher, FetchedItem


class ProductsFetcher(BaseFetcher):
    """ProductHunt + GitHub Trending æ•°æ®è·å–"""

    name = "products"
    name_zh = "äº§å“/å¼€æº"
    icon = "ğŸš€"
    color = "#da552f"

    # AI ç›¸å…³å…³é”®è¯
    AI_KEYWORDS = [
        "ai", "ml", "llm", "gpt", "chatgpt", "claude", "gemini",
        "machine learning", "deep learning", "neural", "transformer",
        "langchain", "vector", "embedding", "rag", "agent",
        "openai", "anthropic", "huggingface", "pytorch", "tensorflow",
    ]

    def fetch(self) -> list[FetchedItem]:
        """è·å–äº§å“å’Œå¼€æºé¡¹ç›®"""
        self.items = []

        # è·å– ProductHunt
        print("  è·å– ProductHunt...")
        ph_items = self._fetch_producthunt()
        self.items.extend(ph_items)

        # è·å– GitHub Trending
        print("  è·å– GitHub Trending...")
        gh_items = self._fetch_github_trending()
        self.items.extend(gh_items)

        # æŒ‰åˆ†æ•°æ’åº
        self.items.sort(key=lambda x: x.fame_score, reverse=True)
        return self.items

    def _fetch_producthunt(self) -> list[FetchedItem]:
        """è·å– ProductHunt çƒ­é—¨äº§å“"""
        items = []

        # ä½¿ç”¨ RSS feed
        try:
            feed = feedparser.parse("https://www.producthunt.com/feed")
            for entry in feed.entries[:20]:
                title = entry.get("title", "")
                summary = entry.get("summary", "")

                # è¿‡æ»¤é AI ç›¸å…³
                if not self._is_ai_related(title + " " + summary):
                    continue

                pub_date = entry.get("published", "")
                if not self.is_within_hours(pub_date, 48):
                    continue

                item = FetchedItem(
                    id=entry.get("id", entry.get("link", "")),
                    title=title,
                    link=entry.get("link", ""),
                    source="ProductHunt",
                    summary=self._clean_html(summary)[:150],
                    pub_date=pub_date,
                    extra={"type": "product"}
                )

                item.tags = self._extract_tags(title + " " + summary)
                item.fame_score = self._calculate_score(item)

                items.append(item)
                print(f"    + [PH] {item.title[:40]}...")

        except Exception as e:
            print(f"    ProductHunt è·å–å¤±è´¥: {e}")

        return items

    def _fetch_github_trending(self) -> list[FetchedItem]:
        """è·å– GitHub Trending é¡¹ç›®"""
        items = []

        try:
            # çˆ¬å– GitHub Trending é¡µé¢
            url = "https://github.com/trending?since=daily"
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"
            }
            resp = requests.get(url, headers=headers, timeout=15)
            soup = BeautifulSoup(resp.text, "html.parser")

            # è§£æé¡¹ç›®åˆ—è¡¨
            articles = soup.select("article.Box-row")

            for article in articles[:30]:
                # è·å–é¡¹ç›®åç§°å’Œé“¾æ¥
                h2 = article.select_one("h2 a")
                if not h2:
                    continue

                repo_path = h2.get("href", "").strip("/")
                if not repo_path:
                    continue

                title = repo_path.replace("/", " / ")
                link = f"https://github.com/{repo_path}"

                # è·å–æè¿°
                desc_elem = article.select_one("p")
                description = desc_elem.get_text(strip=True) if desc_elem else ""

                # è¿‡æ»¤é AI ç›¸å…³
                if not self._is_ai_related(title + " " + description):
                    continue

                # è·å–è¯­è¨€
                lang_elem = article.select_one("[itemprop='programmingLanguage']")
                language = lang_elem.get_text(strip=True) if lang_elem else ""

                # è·å–æ˜Ÿæ ‡æ•°
                stars_elem = article.select_one("a[href$='/stargazers']")
                stars = stars_elem.get_text(strip=True) if stars_elem else ""

                item = FetchedItem(
                    id=repo_path,
                    title=title,
                    link=link,
                    source="GitHub",
                    summary=description[:150] if description else "",
                    extra={
                        "type": "repo",
                        "language": language,
                        "stars": stars,
                    }
                )

                item.tags = self._extract_tags(title + " " + description)
                item.fame_score = self._calculate_score(item)

                items.append(item)
                print(f"    + [GH] {item.title[:40]}...")

        except Exception as e:
            print(f"    GitHub Trending è·å–å¤±è´¥: {e}")

        return items

    def _is_ai_related(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ AI ç›¸å…³"""
        text_lower = text.lower()
        return any(kw in text_lower for kw in self.AI_KEYWORDS)

    @staticmethod
    def _clean_html(html: str) -> str:
        """æ¸…ç† HTML"""
        text = re.sub(r'<[^>]+>', '', html)
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def _extract_tags(self, text: str) -> list:
        """æå–æ ‡ç­¾"""
        tags = []
        text_lower = text.lower()
        seen = set()

        tag_patterns = [
            (r"llm|gpt|claude|gemini", "LLM", "tech"),
            (r"agent", "Agent", "tech"),
            (r"rag|vector|embedding", "RAG", "tech"),
            (r"langchain|llamaindex", "Framework", "tech"),
            (r"python", "Python", "lang"),
            (r"typescript|javascript", "TypeScript", "lang"),
            (r"rust", "Rust", "lang"),
        ]

        for pattern, label, tag_type in tag_patterns:
            if re.search(pattern, text_lower) and label not in seen:
                tags.append({"label": label, "type": tag_type})
                seen.add(label)

        return tags[:4]

    def _calculate_score(self, item: FetchedItem) -> int:
        """è®¡ç®—åˆ†æ•°"""
        score = 0
        text_lower = (item.title + " " + item.summary).lower()

        # å…³é”®è¯æƒé‡
        keyword_weights = {
            "llm": 40, "gpt": 35, "claude": 35, "agent": 35,
            "rag": 30, "langchain": 30, "openai": 40,
            "anthropic": 40, "huggingface": 30,
        }

        for keyword, weight in keyword_weights.items():
            if keyword in text_lower:
                score += weight

        # æ¥æºåŠ åˆ†
        if item.source == "GitHub":
            score += 10
        elif item.source == "ProductHunt":
            score += 15

        return score
