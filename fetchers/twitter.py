import requests
import os
import re
from .base import BaseFetcher, FetchedItem


class TwitterFetcher(BaseFetcher):
    """X/Twitter åŠ¨æ€æ•°æ®è·å–"""

    name = "twitter"
    name_zh = "X/Twitter"
    icon = "ğŸ¦"
    color = "#1da1f2"

    # é‡ç‚¹å…³æ³¨è´¦å·
    ACCOUNTS = {
        "sama": {"name": "Sam Altman", "company": "OpenAI"},
        "kaboris": {"name": "Andrej Karpathy", "company": ""},
        "ylecun": {"name": "Yann LeCun", "company": "Meta"},
        "OpenAI": {"name": "OpenAI", "company": "OpenAI"},
        "AnthropicAI": {"name": "Anthropic", "company": "Anthropic"},
        "GoogleAI": {"name": "Google AI", "company": "Google"},
        "demaboris": {"name": "Demis Hassabis", "company": "DeepMind"},
        "ilonamodei": {"name": "Dario Amodei", "company": "Anthropic"},
    }

    # å…³é”®è¯æƒé‡
    KEYWORD_WEIGHTS = {
        "launch": 50, "release": 50, "announce": 45,
        "gpt": 40, "claude": 40, "gemini": 40,
        "breakthrough": 45, "sota": 40,
        "agent": 30, "reasoning": 35,
        "open source": 35, "api": 25,
    }

    def __init__(self):
        super().__init__()
        # å¯ä»¥ä½¿ç”¨ RapidAPI çš„ Twitter æœåŠ¡
        self.rapidapi_key = os.getenv("RAPIDAPI_KEY", "")

    def fetch(self) -> list[FetchedItem]:
        """è·å– Twitter åŠ¨æ€

        æ³¨æ„ï¼šç”±äº Twitter API é™åˆ¶ï¼Œè¿™é‡Œæä¾›å¤šç§è·å–æ–¹å¼ï¼š
        1. ä½¿ç”¨ RapidAPI Twitter æœåŠ¡
        2. ä½¿ç”¨ Nitter RSSï¼ˆä¸ç¨³å®šï¼‰
        3. æ‰‹åŠ¨é…ç½®çš„é™æ€æ•°æ®
        """
        self.items = []

        # å°è¯•ä» Nitter è·å–ï¼ˆå…è´¹ä½†ä¸ç¨³å®šï¼‰
        for username, info in self.ACCOUNTS.items():
            print(f"  è·å–: @{username} ({info['name']})")
            tweets = self._fetch_nitter(username)

            for tweet in tweets:
                pub_date = tweet.get("published", "")
                if not self.is_within_hours(pub_date, 48):
                    continue

                item = FetchedItem(
                    id=tweet.get("id", ""),
                    title=tweet.get("title", ""),
                    link=tweet.get("link", ""),
                    source=f"@{username}",
                    author=info["name"],
                    pub_date=pub_date,
                    extra={
                        "username": username,
                        "company": info["company"],
                    }
                )

                item.tags = self._extract_tags(item.title)
                item.fame_score = self._calculate_score(item, info)

                self.items.append(item)

        # æŒ‰åˆ†æ•°æ’åº
        self.items.sort(key=lambda x: x.fame_score, reverse=True)
        return self.items

    def _fetch_nitter(self, username: str) -> list:
        """ä» Nitter è·å–æ¨æ–‡ï¼ˆRSSï¼‰"""
        # Nitter å®ä¾‹åˆ—è¡¨ï¼ˆå¯èƒ½ä¸ç¨³å®šï¼‰
        nitter_instances = [
            "nitter.net",
            "nitter.privacydev.net",
            "nitter.poast.org",
        ]

        for instance in nitter_instances:
            try:
                import feedparser
                url = f"https://{instance}/{username}/rss"
                feed = feedparser.parse(url)
                if feed.entries:
                    return feed.entries
            except:
                continue

        return []

    def _fetch_rapidapi(self, username: str) -> list:
        """ä½¿ç”¨ RapidAPI è·å–æ¨æ–‡"""
        if not self.rapidapi_key:
            return []

        url = "https://twitter-api45.p.rapidapi.com/timeline.php"
        headers = {
            "X-RapidAPI-Key": self.rapidapi_key,
            "X-RapidAPI-Host": "twitter-api45.p.rapidapi.com"
        }
        params = {"screenname": username}

        try:
            resp = requests.get(url, headers=headers, params=params, timeout=10)
            data = resp.json()
            return data.get("timeline", [])
        except Exception as e:
            print(f"    RapidAPI è·å–å¤±è´¥: {e}")
            return []

    def _extract_tags(self, text: str) -> list:
        """æå–æ ‡ç­¾"""
        tags = []
        text_lower = text.lower()
        seen = set()

        tag_patterns = [
            (r"openai|gpt", "OpenAI", "company"),
            (r"anthropic|claude", "Anthropic", "company"),
            (r"google|gemini", "Google", "company"),
            (r"launch|release|announce", "å‘å¸ƒ", "event"),
            (r"agent", "Agent", "topic"),
        ]

        for pattern, label, tag_type in tag_patterns:
            if re.search(pattern, text_lower) and label not in seen:
                tags.append({"label": label, "type": tag_type})
                seen.add(label)

        return tags[:3]

    def _calculate_score(self, item: FetchedItem, account_info: dict) -> int:
        """è®¡ç®—æ¨æ–‡åˆ†æ•°"""
        score = 0
        text_lower = item.title.lower()

        # å…³é”®è¯æƒé‡
        for keyword, weight in self.KEYWORD_WEIGHTS.items():
            if keyword in text_lower:
                score += weight

        # è´¦å·æƒé‡
        account_weights = {
            "sama": 50,
            "kaboris": 45,
            "OpenAI": 40,
            "AnthropicAI": 40,
            "GoogleAI": 35,
        }
        score += account_weights.get(item.extra.get("username", ""), 20)

        return score
